import csv
import os
from datetime import datetime
from time import sleep

from dotenv import load_dotenv
from pocketflow import Node

from agent.tools.summary import generate_news_summary_report
from agent.utils import get_images, call_llm
import yaml

load_dotenv()

__all__ = ["SupervisorNode", "ImageMatchScorer", "ContentSummarizer"]


class ContentSummarizer(Node):
    def prep(self, shared):
        """è·å–ç”¨äºå›ç­”çš„é—®é¢˜å’Œä¸Šä¸‹æ–‡ã€‚"""
        search_volume = shared["search_volume"]
        search_growth_rate = shared["search_growth_rate"]
        search_active_time = shared["search_active_time"]
        return shared['current_date'], shared[
            "hot_word"], search_volume, search_growth_rate, search_active_time, shared.get(
            "context"), shared.get("language"), shared["logger"]

    def exec(self, inputs):
        """è°ƒç”¨ LLM ç¼–åˆ¶è‰ç¨¿ã€‚"""
        current_date, hot_word, search_volume, search_growth_rate, search_active_time, context, language, logger = inputs
        current_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        desc = f"æ­¤çƒ­è¯ä»{search_active_time}å¼€å§‹æœç´¢æ´»è·ƒ,æœç´¢é‡ä¸Šå‡{search_growth_rate},æœç´¢æ€»é‡è¾¾åˆ°{search_volume}"

        logger.info(f"ç¼–åˆ¶è‰ç¨¿...")

        # ä¸º LLM åˆ›å»ºä¸€ä¸ªæç¤ºä»¥åŸºäºç½‘ç»œç ”ç©¶å†…å®¹ç¼–å†™è‰ç¨¿
        prompt = f"""
## ä¸Šä¸‹æ–‡

ä½ æ˜¯ä¸€ä¸ªçƒ­ç‚¹ä¿¡æ¯ç²¾ç‚¼åŠ©æ‰‹ï¼ŒåŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œå›ç­”é—®é¢˜ã€‚

### ç²¾ç‚¼ç»´åº¦

- æ ¸å¿ƒäº‹å®æå–: ä»æµ·é‡ä¿¡æ¯ä¸­æå–å…³é”®äº‹å®è¦ç´ 
- èˆ†æƒ…è„‰ç»œæ¢³ç†: æ¢³ç†å…¬ä¼—æƒ…ç»ªå˜åŒ–ä¸è®¨è®ºç„¦ç‚¹è½¬ç§»è·¯å¾„
- å‘é…µç‚¹è¯†åˆ«: è¯†åˆ«æ¨åŠ¨è¯é¢˜æ‰©æ•£çš„å…³é”®èŠ‚ç‚¹ä¸è§¦å‘å› ç´ 
- è¶‹åŠ¿é¢„åˆ¤: åŸºäºç°æœ‰ä¿¡æ¯é¢„æµ‹è¯é¢˜å¯èƒ½çš„å‘å±•æ–¹å‘

### è¾“å…¥æ ¼å¼:

å½“å‰æ—¶é—´: {current_date}
æ—¶ä¸‹æµè¡Œçƒ­è¯: 
{hot_word}
{desc}

ç›¸å…³ç ”ç©¶: 

{context}

### ä½ çš„å›ç­”:
1. è¯·æ ¹æ®ç ”ç©¶å†…å®¹æ’°å†™å¦‚ä¸‹ä¸¤éƒ¨åˆ†å™äº‹æ–‡æ¡ˆï¼š
   - ä¸­æ–‡å™äº‹ (`chinese`)
   - {language}å™äº‹ (`output`)
   - å†…å®¹è¦æ±‚ï¼š
     * ä½¿ç”¨æ—¥å¸¸è¯­è¨€ï¼Œé¿å…æœ¯è¯­
     * æ¶µç›–æ ¸å¿ƒäº‹å®ã€èˆ†æƒ…è„‰ç»œã€å‘é…µç‚¹åŠè¶‹åŠ¿é¢„åˆ¤ç­‰ç»´åº¦
     * æ¯æ®µä¿æŒç»“æ„æ¸…æ™°ï¼Œé€»è¾‘é€šé¡º

2. åŒæ—¶ï¼Œè¯·ä»ç ”ç©¶å†…å®¹ä¸­æå– **2ä¸ªæœ€ç›¸å…³çš„ä¼˜è´¨æŠ¥é“æ‘˜è¦**ï¼Œå¹¶è¿”å›ä»¥ä¸‹ç»“æ„ï¼š

```yaml
highlights: 
  - title: <æŠ¥é“æ ‡é¢˜1,ä½¿ç”¨{language}> 
    summary: <æ‘˜è¦,ä½¿ç”¨{language}> 
    link: "<æ¥æºé“¾æ¥,é“¾æ¥ä½¿ç”¨å¼•å·>"
  - title: <æŠ¥é“æ ‡é¢˜2,ä½¿ç”¨{language}> 
    summary: <æ‘˜è¦,ä½¿ç”¨{language}> 
    link: "<æ¥æºé“¾æ¥,é“¾æ¥ä½¿ç”¨å¼•å·>"
chinese: |
    <ä¸­æ–‡å™äº‹æ–‡æ¡ˆ>
output: |
    <{language}å™äº‹æ–‡æ¡ˆ,æ³¨æ„æ­¤éƒ¨åˆ†æ–‡æ¡ˆä½¿ç”¨{language}>
```

é‡è¦ï¼šè¯·ç¡®ä¿ï¼š
âš ï¸ YAML æ ¼å¼è¦æ±‚ï¼š
- æ‰€æœ‰å­—æ®µä½¿ç”¨è‹±æ–‡å†’å· `:` + **ä¸€ä¸ªç©ºæ ¼** å¼€å§‹å€¼
- å¤šè¡Œå­—æ®µä½¿ç”¨ `|` è¡¨ç¤ºï¼Œå¹¶è‡³å°‘æ¯”é”®åå¤šä¸€çº§ç¼©è¿›ï¼ˆæ¨è 4 ä¸ªç©ºæ ¼ï¼‰
- åˆ—è¡¨é¡¹ï¼ˆ`-`ï¼‰éœ€ç»Ÿä¸€ç¼©è¿›
- ä¸å…è®¸åœ¨ `title:`ã€`summary:`ã€`link:` åç›´æ¥åµŒå¥—æ–°ç»“æ„
- é¿å…ä½¿ç”¨ä¸­æ–‡å†’å· `ï¼š` æˆ–çœç•¥ç©ºæ ¼
- ä¸è¦å¯¹ `chinese` å’Œ `output` å­—æ®µè¿›è¡ŒåµŒå¥—æˆ–æ·»åŠ é¢å¤–ç»“æ„
        """
        # è°ƒç”¨ LLM ç”Ÿæˆè‰ç¨¿
        search_data, success = call_llm(prompt, logger)
        if "```yaml" not in search_data:
            logger.error("LLM å“åº”æ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·æ£€æŸ¥ä½ çš„å“åº”æ ¼å¼ã€‚")
            return {"action": "finish", "reason": "LLM å“åº”æ ¼å¼ä¸æ­£ç¡®"}
        try:
            yaml_str = search_data.split("```yaml")[1].split("```")[0].strip()
        except Exception as e:
            return {"action": "finish", "reason": "LLM å“åº”æ ¼å¼ä¸æ­£ç¡®"}
        logger.info(f"LLM å“åº”: \n {yaml_str}")
        response = yaml.safe_load(yaml_str)
        if not success:
            logger.error("LLM å“åº”å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä½ çš„å“åº”æ ¼å¼ã€‚")
            return {"action": "finish", "reason": "LLM å“åº”å¤±è´¥"}

        return search_data, response

    def post(self, shared, prep_res, exec_res):
        """ä¿å­˜æœ€ç»ˆå›ç­”å¹¶å®Œæˆæµç¨‹ã€‚"""
        # åœ¨å…±äº«å­˜å‚¨ä¸­ä¿å­˜å›ç­”

        search_data, response = exec_res
        shared['chinese'] = response['chinese']
        output = response['output']
        shared['output'] = output
        highlights = response.get('highlights', [])
        if highlights:
            highlights_str = "\n".join([
                f"{index}.ğŸŒæŠ¥é“æ ‡é¢˜åŠé“¾æ¥:\n[{highlight['title']}]({highlight['link']})\næ‘˜è¦ï¼š\n{highlight['summary']}\n\n"
                for index, highlight in enumerate(highlights, start=1)
            ])
        else:
            highlights_str = ""
        shared['highlights'] = highlights_str  # å­˜å…¥ä¼˜è´¨æŠ¥é“åˆ—è¡¨
        logger = shared["logger"]
        shared['search_data'] = search_data

        logger.info(f"âœ… ä¼˜è´¨æ–°é—»æå–æˆåŠŸ{highlights_str}")

        hot_word_info = {
            'search_volume': shared["search_volume"],
            'search_growth_rate': shared["search_growth_rate"],
            'search_active_time': shared["search_active_time"],
            'current_date': shared['current_date']
        }

        generate_news_summary_report(highlights_str, output, shared['hot_word_path'], hot_word_info, logger,
                                     shared['language'])

        logger.info(f"âœ… ç”Ÿæˆmarkdownæ±‡æ€»æ–‡æ¡£{highlights_str}")


# ç›‘ç£èŠ‚ç‚¹
class SupervisorNode(Node):
    def prep(self, shared):
        """è·å–å½“å‰å›ç­”ä»¥è¿›è¡Œè¯„ä¼°ã€‚"""
        return shared["search_data"], shared["logger"]

    def exec(self, inputs):
        """æ£€æŸ¥å›ç­”æ˜¯å¦æœ‰æ•ˆæˆ–æ— æ„ä¹‰ã€‚"""
        search_data, logger = inputs
        logger.info(f"ç›‘ç£å‘˜æ­£åœ¨æ£€æŸ¥å›ç­”è´¨é‡...")

        # æ£€æŸ¥æ— æ„ä¹‰å›ç­”çš„æ˜æ˜¾æ ‡è®°
        nonsense_markers = [
            "coffee break",
            "purple unicorns",
            "made up",
            "42",
            "Who knows?"
        ]

        # æ£€æŸ¥å›ç­”æ˜¯å¦åŒ…å«ä»»ä½•æ— æ„ä¹‰æ ‡è®°
        is_nonsense = any(marker in search_data for marker in nonsense_markers)

        if is_nonsense:
            return {"valid": False, "reason": "å›ç­”ä¼¼ä¹æ— æ„ä¹‰æˆ–æ— å¸®åŠ©"}
        else:

            return {"valid": True, "reason": "å›ç­”ä¼¼ä¹æ˜¯åˆæ³•çš„"}

    def post(self, shared, prep_res, exec_res):
        logger = shared["logger"]
        """å†³å®šæ˜¯å¦æ¥å—å›ç­”æˆ–é‡æ–°å¯åŠ¨æµç¨‹ã€‚"""
        if exec_res["valid"]:
            logger.info(f"ç›‘ç£å‘˜æ‰¹å‡†äº†å›ç­”: {exec_res['reason']}")
            hot_word_path = shared["hot_word_path"]
            hot_word = shared["hot_word"]
            relation_news = shared["relation_news"]
            search_history = shared["search_history"]
            highlights = shared['highlights']
            current_path = os.path.dirname(os.path.dirname(os.path.dirname(__name__)))
            hot_words_csv = os.path.join(current_path, os.path.dirname(hot_word_path), os.getenv("HOT_WORDS_FILE_NAME"))
            # ç¡®ä¿ hot_word_path æ˜¯æœ‰æ•ˆçš„è·¯å¾„
            # å°† hot_word_pathã€hot_word å’Œ exec_res å†™å…¥ CSV æ–‡ä»¶
            try:
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºæ–‡ä»¶å¹¶å†™å…¥è¡¨å¤´
                file_exists = os.path.isfile(hot_words_csv)
                data = []

                if file_exists:
                    # è¯»å–ç°æœ‰æ•°æ®
                    with open(hot_words_csv, 'r', newline='', encoding='utf-8-sig') as csvfile:
                        reader = csv.DictReader(csvfile)
                        # æ£€æŸ¥æ˜¯å¦åŒ…å« 'final_article' åˆ—
                        # æ£€æŸ¥æ˜¯å¦åŒ…å« 'final_article' åˆ—
                        for row in reader:
                            if row['hot_word'] == hot_word:
                                # å¦‚æœ hot_word å­˜åœ¨ï¼Œè¿½åŠ  final_article
                                row_tmp = {
                                    "hot_word": row['hot_word'],
                                    'search_volume': row['search_volume'],
                                    'search_growth_rate': row['search_growth_rate'],
                                    "search_active_time": row['search_active_time'],
                                    'relation_news': row['relation_news'],
                                    'search_history': shared['search_history'],
                                    'chinese': shared['chinese'],
                                    'output': shared['output'],
                                    'highlights': shared['highlights'],
                                }
                            else:
                                row_tmp = {
                                    "hot_word": row['hot_word'],
                                    'search_volume': row['search_volume'],
                                    'search_growth_rate': row['search_growth_rate'],
                                    "search_active_time": row['search_active_time'],
                                    'relation_news': row['relation_news'],
                                    'search_history': row['search_history'],
                                    'chinese': row['chinese'],
                                    'output': row['output'],
                                    'highlights': row['highlights']
                                }
                            data.append(row_tmp)
                else:
                    # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–‡ä»¶å¹¶å†™å…¥è¡¨å¤´
                    data.append({'hot_word': hot_word, 'relation_news': relation_news, 'search_history': search_history,
                                 'highlights': highlights,
                                 'chinese': shared['chinese'], 'output': shared['output']})
                logger.info(f"====CSVä¿å­˜æ•°æ®ï¼š{data}===")

                # å†™å…¥æ•°æ®
                with open(hot_words_csv, 'w', newline='', encoding='utf-8-sig') as csvfile:
                    fieldnames = ['hot_word',
                          'search_volume',
                          'search_growth_rate',
                          "search_active_time",
                          "relation_news",
                          "search_history",
                          "highlights",
                          "chinese",
                          "output", ]
                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(data)

                logger.info(f"====çƒ­è¯æ–°é—»ã€æœç´¢ç ”ç©¶å†å²æ•°æ®ã€è‰ç¨¿æ•°æ®å·²å†™å…¥ CSV æ–‡ä»¶: {hot_words_csv}===")
            except Exception as e:
                logger.error(f"å†™å…¥ CSV æ–‡ä»¶æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            return "approved"
        else:
            logger.info(f"ç›‘ç£å‘˜æ‹’ç»äº†å›ç­”: {exec_res['reason']}")
            # æ¸…ç†é”™è¯¯çš„å›ç­”
            shared["answer"] = None
            # æ·»åŠ å…³äºè¢«æ‹’ç»å›ç­”çš„æ³¨é‡Š
            context = shared.get("context", "")
            shared["context"] = context + "\n\næ³¨æ„: ä¹‹å‰çš„å›ç­”å°è¯•è¢«ç›‘ç£å‘˜æ‹’ç»äº†ã€‚"

            return "retry"


class ImageMatchScorer(Node):
    def prep(self, shared):
        """
        ä»å…±äº«æ•°æ®ä¸­è·å–æœ€ç»ˆæ–‡ç« å’Œçƒ­è¯è·¯å¾„
        """
        return shared["chinese"], shared["hot_word_path"], shared["logger"]

    def exec(self, inputs):
        """
        å¯¹æ–‡ç« åº”ç”¨ç‰¹å®šé£æ ¼
        """
        chinese, hot_word_path, logger = inputs
        prompt = f"""
        ## ä¸Šä¸‹æ–‡
        ä½ æ˜¯ä¸€ä¸ªå†…å®¹é…å›¾è¯„åˆ†åŠ©æ‰‹

        ## æ“ä½œç©ºé—´
        è¯·æ ¹æ®ä»¥ä¸‹æŒ‡æ ‡å¯¹å†…å®¹çš„é…å›¾è¿›è¡Œè¯„åˆ†
        å†…å®¹ï¼š{chinese}

        è¯„åˆ†æŒ‡æ ‡ï¼ˆæ¯ä¸ªæŒ‡æ ‡1-10åˆ† æ•´æ•°ï¼‰ï¼š
        - ç›¸å…³æ€§ï¼šå›¾ç‰‡æ˜¯å¦ä¸æ–‡ç« å†…å®¹ç›¸å…³ã€‚
        - å¸å¼•åŠ›ï¼šå›¾ç‰‡æ˜¯å¦èƒ½å¸å¼•ç”¨æˆ·çœ¼çƒã€‚
        - è§†è§‰æ•ˆæœï¼šå›¾ç‰‡çš„è‰²å½©ã€æ„å›¾å’Œæ¸…æ™°åº¦å¦‚ä½•ã€‚
        - æƒ…æ„Ÿå…±é¸£ï¼šå›¾ç‰‡æ˜¯å¦èƒ½å¼•å‘è§‚ä¼—çš„æƒ…æ„Ÿå…±é¸£ã€‚

        ## ä¸‹ä¸€æ­¥æ“ä½œ
         é‡è¦ï¼šè¯·ç¡®ä¿ï¼š
         ä¸¥æ ¼ä»¥ä¸‹æ ¼å¼è¿”å›ä½ çš„å“åº”,æ— éœ€å…¶ä½™ä¿¡æ¯ï¼š
         æ¯ä¸ªå€¼ä¸ä¸ºç©ºï¼Œä¸”æ¯ä¸ªå­—æ®µéƒ½åŒ…å«ä¸€ä¸ªæ•´æ•°å€¼ã€‚

        ```yaml
        total_score: <æ€»åˆ†>
        relevance: <ç›¸å…³æ€§-æŒ‡æ ‡åˆ†æ•°>
        attractiveness: <å¸å¼•åŠ›-æŒ‡æ ‡åˆ†æ•°>
        visual: <è§†è§‰æ•ˆæœ-æŒ‡æ ‡åˆ†æ•°>
        emotional: <æƒ…æ„Ÿå…±é¸£-æŒ‡æ ‡åˆ†æ•°>
        ```
        
        é‡è¦ï¼šè¯·ç¡®ä¿ï¼š
        1. å¯¹æ‰€æœ‰å¤šè¡Œå­—æ®µä½¿ç”¨é€‚å½“çš„ç¼©è¿›ï¼ˆ4ä¸ªç©ºæ ¼ï¼‰
        2. ä½¿ç”¨|å­—ç¬¦è¡¨ç¤ºå¤šè¡Œæ–‡æœ¬å­—æ®µ
        3. ä¿æŒå•è¡Œå­—æ®µä¸ä½¿ç”¨|å­—ç¬¦
        4. æ­£ç¡®ä½¿ç”¨YAMLå­—ç¬¦ä¸²æ ¼å¼
        """

        result_list = []
        images_list = get_images(hot_word_path)
        if len(images_list) > 8:  # //åªè¯„ä¼°8å¼ å›¾ç‰‡
            images_list = images_list[:8]
        for image_path in images_list:
            sleep(5)
            response, success = call_llm(prompt, logger, image_path)
            if not success:
                logger.error("LLM è°ƒç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä½ çš„é…ç½®ã€‚")
                return {"action": "finish", "reason": "LLM è°ƒç”¨å¤±è´¥"}
            logger.info(f"LLM å“åº”: {response}")
            if "```yaml" not in response:
                logger.error("LLM å“åº”æ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·æ£€æŸ¥ä½ çš„å“åº”æ ¼å¼ã€‚")
                return {"action": "finish", "reason": "LLM å“åº”æ ¼å¼ä¸æ­£ç¡®"}
            try:
                yaml_str = response.split("```yaml")[1].split("```")[0].strip()
                decision = yaml.safe_load(yaml_str)
            except Exception as e:
                logger.error(f"å¤„ç† LLM å“åº”æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                continue

            if isinstance(decision, dict) and "total_score" in decision:
                # æå–æ€»åˆ†å¹¶é‡å‘½åå›¾ç‰‡
                try:
                    total_score = int(decision["total_score"])
                except ValueError:
                    logger.error(f"æ— æ³•å°† total_score è½¬æ¢ä¸ºæ•´æ•°: {decision['total_score']}")
                    continue
                image_name = os.path.basename(image_path)
                new_image_name = f"{total_score}_{image_name}"
                new_image_path = os.path.join(hot_word_path, new_image_name)
                try:
                    os.rename(image_path, new_image_path)
                    logger.info(f"å›¾ç‰‡å·²é‡å‘½åä¸º: {new_image_name}")
                except Exception as e:
                    logger.error(f"é‡å‘½åå›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            result_list.append(decision)

        return result_list

    def post(self, shared, prep_res, exec_res):
        """
        å°†æœ€ç»ˆæ–‡ç« å­˜å‚¨åœ¨å…±äº«æ•°æ®ä¸­
        """
        shared["evaluate_image_result_list"] = exec_res
        logger = shared["logger"]
        logger.info(f"===å›¾ç‰‡è¯„åˆ†å·²ç»å®Œæˆ===")
        return "default"


if __name__ == "__main__":
    current_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    print(current_dir)
    hot_words_csv = os.path.join(current_dir, "tasks/2025å¹´04æœˆ27æ—¥18æ—¶50åˆ†/hot_words.csv")
    hot_word = "will howard"
    exec_res = "222"
    # åˆ›å»ºä»£ç†æµç¨‹
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºæ–‡ä»¶å¹¶å†™å…¥è¡¨å¤´
        file_exists = os.path.isfile(hot_words_csv)
        data = []

        if file_exists:
            # è¯»å–ç°æœ‰æ•°æ®
            with open(hot_words_csv, 'r', newline='', encoding='utf-8-sig') as csvfile:
                reader = csv.DictReader(csvfile)
                fieldnames = reader.fieldnames
                # æ£€æŸ¥æ˜¯å¦åŒ…å« 'final_article' åˆ—
                # æ£€æŸ¥æ˜¯å¦åŒ…å« 'final_article' åˆ—
                if 'final_article' not in fieldnames:
                    # å¦‚æœç¼ºå°‘ 'final_article' åˆ—ï¼Œåˆ›å»ºæ–°çš„ fieldnames
                    new_fieldnames = fieldnames + ['final_article']
                    for row in reader:
                        # åˆå§‹åŒ– 'final_article' åˆ—ä¸ºç©ºå­—ç¬¦ä¸²
                        row['final_article'] = ''
                        data.append(row)
                    fieldnames = new_fieldnames
                else:
                    # å¦‚æœåŒ…å« 'final_article' åˆ—ï¼Œæ­£å¸¸è¯»å–æ•°æ®
                    for row in reader:
                        if row['hot_word'] == hot_word:
                            # å¦‚æœ hot_word å­˜åœ¨ï¼Œè¿½åŠ  final_article
                            row['final_article'] += "\n" + exec_res
                        data.append(row)
        else:
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–‡ä»¶å¹¶å†™å…¥è¡¨å¤´
            fieldnames = ['hot_word', 'final_article']
            data.append({'hot_word': hot_word, 'final_article': exec_res})

        # å†™å…¥æ•°æ®
        with open(hot_words_csv, 'w', newline='', encoding='utf-8-sig') as csvfile:
            fieldnames = ['hot_word', 'final_article']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(data)

        print(f"æ•°æ®å·²å†™å…¥ CSV æ–‡ä»¶: {hot_words_csv}")
    except Exception as e:
        print(f"å†™å…¥ CSV æ–‡ä»¶æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
